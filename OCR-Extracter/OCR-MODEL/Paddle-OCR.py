from pathlib import Path
from typing import Optional, Union
import numpy as np
import pandas as pd
import re
import os
import json

# customer struct data
QuestionData = list[Optional[Union[str, bool]]]

class PaddleOCR_Extracter:
    # PATH
    BASE_PATH: Path = Path.cwd().parent.parent # Workstation root directory
    
    def __init__(self, fold_name: str) -> None:
        '''
        Args:
            fold_name: The folder containing the all content you need to extract. Note: Must be located in the `input` folder within the project's root directory.
        '''
        self.INPUT_FOLD_NAME: Path = self.BASE_PATH / 'input' / fold_name
        self.OUTPUT_FOLD_NAME: Path = self.BASE_PATH / 'output' / fold_name
        return None

    
    def _extract_image_to_json(self) -> None:
        '''
        Using paddle to fetch one image content and stored it to a json file.
        '''
        
        img_path = self.INPUT_FOLD_NAME
        output_json_path = self.OUTPUT_FOLD_NAME / 'json'
        if not Path.is_dir(img_path):
            print(f"{img_path} input fold is not a fold or exists")
            return

        # Recommended to import necessary dependency packages in this function 
        # instead of at the beginning of the file 
        # to avoid frequent loading of data packages during instance creation. 
        # Also, avoid loading Paddle OCR when it is not needed, 
        # and avoiding wasting resources.
        import paddle
        from paddleocr import PaddleOCR
        
        
        # Check out your cuda compiled
        if paddle.device.is_compiled_with_cuda():
            print(f"Using GPU for acceleration... (Images: {img_path})")
        else:
            print(f"Using CPU... (Images: {img_path})")

        # Initialize OCR
        ocr = PaddleOCR(
            lang='ch',
            use_doc_orientation_classify=False,
            use_doc_unwarping=False,
            use_textline_orientation=False,
            enable_mkldnn=False 
        )

        # Run OCR identification
        try:
            result = ocr.predict(input=str(img_path))
        except Exception as error:
            print(error)
            return
            

        # Save the result using the .save_to_json() method
        if result:
            # Ensure output directory exists before saving
            
            os.makedirs(os.path.dirname(output_json_path), exist_ok=True)
            for res in result:
                # This will save the result of the first page (or only page)
                # and overwrite if multiple pages are in the result.
                # Assuming one page per image.
                res.save_to_json(output_json_path)
        else:
            print(f"No OCR result for image: {img_path}")

    
    def extract_all_contents(self) -> list[str]:
        '''
        Extract the content from all JSON files generated by OCR technology
        write this content into the corresponding `txt` files within the `input` files
        and then save all the content into a list[str[].
        '''
        
        def extract_contents(json_file: Path) -> list[str]:
            '''Reads One JSON file that has been OCRed JSON output and returns a list of text lines that include all total content.'''
            
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
            
                rec_texts_list: list[str] = data['rec_texts']
        
                # Optional: Save raw text for debugging
                debug_txt_file = json_file.parent.parent / 'extracted_total_contents.txt'
                with open(debug_txt_file, '+a', encoding='utf-8') as f:
                    f.write('\n=========================================================\n')
                    content_to_write = '\n'.join(rec_texts_list)
                    f.write(content_to_write)
            
                return rec_texts_list
        
            except FileNotFoundError:
                print(f"Error: JSON file not found at {json_file}")
                return []
            except KeyError:
                print(f"Error: 'rec_texts' key not found in {json_file}. The JSON structure might be different.")
                return []
        
        
        JSON_FOLD = self.OUTPUT_FOLD_NAME / 'json'
        total_contents = []
        
        for item_file in sorted(JSON_FOLD.iterdir()):
            if item_file.suffix == '.json':
                # print(f"file name: {item_file}") # Debugger file order
                total_contents.append(extract_contents(item_file))
            
        return [item for sub_content in total_contents for item in sub_content]
        
    
    def structure_questions(self, text_lines: list[str]) -> list[QuestionData]:
        """
        Parses raw OCR text lines into a structured list of questions.
        1. Combine multiple lines of questions into a single element of a list.
        2. Place options A, B, C, and D into separate list elements.
        
        Return:
            list[QuestionData]
            QuestionData content is ['题目', 'A', 'B', 'C', 'D', '多选', '正确答案'].
        """
        # Helper function to clean and store an option in the correct index.
        def store_option(question_list: QuestionData, option_text: str) -> None:
            """Helper function to clean and store an option in the correct index."""
            option_text = option_text.strip()
            # print(f"option text: {option_text}") # debugger code
            if not option_text:
                return
        
            if option_text[0] in option_map:
                option_char: str = option_text[0]
                index: int = option_map[option_char]
                clean_text: str = option_clean_re.sub('', option_text).strip()
                
                # Fixed a bug caused by incorrect question extraction.
                if question_list[index] != None:
                    raise ValueError("Question recognition error")

                if 0 <= index < len(question_list):
                    question_list[index] = clean_text
                    
                return


        # --- 1. Regex Definitions ---
        new_item_re = re.compile(r'^(?:\d+\.|[ABCD]\.)\s*')
        question_stem_re = re.compile(r'^\d+\.\s*')
        multi_option_find_re = re.compile(r'[ABCD]\.\s*')
        multi_option_split_re = re.compile(r'(?=[ABCD]\.\s*)')
        option_clean_re = re.compile(r'^[ABCD]\.\s*')

    
        # --- 2. Pass 1: Merge Continuation Text ---
        merged_lines: list[str] = []
        for line in text_lines:
            # print(f"line: {line}") # debugger cod3
            line = line.strip()
            if not line:
                continue
        
            if new_item_re.search(line) or not merged_lines:
                merged_lines.append(line)
            else:
                merged_lines[-1] += "" + line


        # # debugger code
        # for line in merged_lines:
        #     print(f"merged line: {line}")
            
            
        # --- 3. Pass 2: Structure into Question lists ---
        all_questions: list[QuestionData] = []
        option_map: dict[str, int] = {'A': 1, 'B': 2, 'C': 3, 'D': 4}
        # --- Main Loop for Pass 2 ---
        for line in merged_lines:
            if question_stem_re.search(line):
                # --- MODIFIED: Create QuestionData list ---
                stem_text = question_stem_re.sub('', line).strip()
                
                # # Check for multiple choice keywords
                # is_multi = "multiple selection" in stem_text.lower() or "多选" in stem_text

                current_question_list: QuestionData = [
                    stem_text,  # 0: stem
                    None,       # 1: A
                    None,       # 2: B
                    None,       # 3: C
                    None,       # 4: D
                ]
                all_questions.append(current_question_list)
        
            elif all_questions: # Only process options if a question has been started
                # This line is potentially an option
                active_question_list: QuestionData = all_questions[-1]
                
                # check one line whether include two or more choice
                option_matches = multi_option_find_re.findall(line)
                try:
                    if len(option_matches) >= 2:
                        split_parts: list[str] = multi_option_split_re.split(line)
                        for part in split_parts:
                            store_option(active_question_list, part)
                    elif len(option_matches) == 1 and line.startswith(tuple(option_map.keys())):
                        store_option(active_question_list, line)
                except ValueError as error:
                    print(f"{error}, The error occurred in question {len(all_questions) + 1}.")
                    current_question_list: QuestionData = [
                        'Errrrrrrrrrrrrrrrrrrrrrrrrrrrrror',  # 0: stem
                        None,       # 1: A
                        None,       # 2: B
                        None,       # 3: C
                        None,       # 4: D
                    ]
                    all_questions.append(current_question_list)
                    store_option(all_questions[-1], line)
                
                    
                
                
                # # debgger code
                # if line == "A.①②":
                #     print("Hello Debugger")
                #     # check one line whether include two or more choice
                #     option_matches = multi_option_find_re.findall(line)
            
                #     if len(option_matches) >= 2:
                #         split_parts: list[str] = multi_option_split_re.split(line)
                #         for part in split_parts:
                #             store_option(active_question_list, part)
                #     elif len(option_matches) == 1 and line.startswith(tuple(option_map.keys())):
                #         store_option(active_question_list, line)
                #     else:
                #         print("test")
                        
                #     # print(active_question_list)
                #     # print(all_questions[-1])
                # else:
                #     # check one line whether include two or more choice
                #     option_matches = multi_option_find_re.findall(line)
            
                #     if len(option_matches) >= 2:
                #         split_parts: list[str] = multi_option_split_re.split(line)
                #         for part in split_parts:
                #             store_option(active_question_list, part)
                #     elif len(option_matches) == 1 and line.startswith(tuple(option_map.keys())):
                #         store_option(active_question_list, line)
                #     print(all_questions[-1] if '邓小平曾经' in str(all_questions[-1][0]) else None)
                    
                    
                
        # Log file
        debug_txt_file = self.OUTPUT_FOLD_NAME / 'structed_contents.txt'
        with open(debug_txt_file, '+a', encoding='utf-8') as f:
            for question in all_questions:
                f.write("\n========================================")
                for line in question:
                    content_to_write = '\n' + str(line)
                    f.write(content_to_write)
        
        return all_questions



if __name__ == '__main__':
    # Class
    class Excel_Exector:
        def __init__(self):
            self.BASE_PATH: Path = Path.cwd()
            return
    
    
        def store_excel(self, question_lists: list[QuestionData]):
            output_file = self.BASE_PATH.parent.parent / 'output' / 'data.xlsx'
            output_file_csv = self.BASE_PATH.parent.parent / 'output' / 'data.csv'

            # Create DataFrame (optional: add column names)
            df = pd.DataFrame(question_lists, columns=['题目', 'A', 'B', 'C', 'D'])

            # Write to Excel
            df.to_excel(output_file, 
                        sheet_name='Reshaped Data', 
                        index=False) # Excludes the DataFrame's row index (0, 1, 2, 3)

            df.to_csv(output_file_csv, 
                        index=False,
                        encoding='utf-8') # Excludes the DataFrame's row index (0, 1, 2, 3)
            print(f"\nData successfully written to {output_file}")
    
    
    print("start running...")
    P = PaddleOCR_Extracter('chapter2/singal')
    # P._extract_image_to_json()
    
    structed_line = P.structure_questions(P.extract_all_contents())
    
    
    E = Excel_Exector()
    E.store_excel(structed_line)